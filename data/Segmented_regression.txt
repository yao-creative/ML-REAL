segmented regression, also known as piecewise regression or broken-stick regression, is a method in regression analysis in which the independent variable is partitioned into intervals and a separate line segment is fit to each interval. segmented regression analysis can also be performed on multivariate data by partitioning the various independent variables. segmented regression is useful when the independent variables, clustered into different groups, exhibit different relationships between the variables in these regions. the boundaries between the segments are breakpoints.
segmented linear regression is segmented regression whereby the relations in the intervals  are obtained by linear regression.


== segmented linear regression, two segments ==

segmented linear regression with two segments separated by a breakpoint can be useful to quantify an abrupt change of the response function (yr) of a varying influential factor (x).  the breakpoint can be interpreted as a critical, safe, or threshold value beyond or below which (un)desired effects occur. the breakpoint can be important in decision making the figures illustrate some of the results and regression types obtainable.
a segmented regression analysis is based on the presence of a set of ( y, x ) data, in which y is the dependent variable and x the independent variable.
the least squares method applied separately to each segment, by which the two regression lines are made to fit the data set as closely as possible while minimizing the sum of squares of the differences (ssd) between observed (y) and calculated (yr) values of the dependent variable, results in the following two equations:

yr = a1.x + k1     for x < bp (breakpoint)
yr = a2.x + k2     for x > bp (breakpoint)where:
yr is the expected (predicted) value of y for a certain value of x;
a1 and a2 are regression coefficients (indicating the slope of the line segments);
k1 and k2 are regression constants (indicating the intercept at the y-axis).the data may show many types or trends, see the figures.
the method also yields two correlation coefficients (r):

  
    
      
        
          r
          
            1
          
          
            2
          
        
        =
        1
        −
        
          
            
              ∑
              (
              y
              −
              
                y
                
                  r
                
              
              
                )
                
                  2
                
              
            
            
              ∑
              (
              y
              −
              
                y
                
                  a
                  1
                
              
              
                )
                
                  2
                
              
            
          
        
      
    
    {\displaystyle r_{1}^{2}=1-{\frac {\sum (y-y_{r})^{2}}{\sum (y-y_{a1})^{2}}}}
       for x < bp (breakpoint)and

  
    
      
        
          r
          
            2
          
          
            2
          
        
        =
        1
        −
        
          
            
              ∑
              (
              y
              −
              
                y
                
                  r
                
              
              
                )
                
                  2
                
              
            
            
              ∑
              (
              y
              −
              
                y
                
                  a
                  2
                
              
              
                )
                
                  2
                
              
            
          
        
      
    
    {\displaystyle r_{2}^{2}=1-{\frac {\sum (y-y_{r})^{2}}{\sum (y-y_{a2})^{2}}}}
        for x > bp (breakpoint)where:

  
    
      
        ∑
        (
        y
        −
        
          y
          
            r
          
        
        
          )
          
            2
          
        
      
    
    {\displaystyle \sum (y-y_{r})^{2}}
   is the minimized ssd per segmentand

ya1 and ya2 are the average values of y in the respective segments.in the determination of the most suitable trend, statistical tests must be performed to ensure that this trend is reliable (significant).
when no significant breakpoint can be detected, one must fall back on a regression without breakpoint.


== example ==

for the blue figure at the right that gives the relation between yield of mustard (yr = ym, t/ha) and soil salinity (x = ss, expressed as electric conductivity of the soil solution ec in ds/m) it is found that:bp = 4.93, a1 = 0, k1 = 1.74, a2 = −0.129, k2 = 2.38, r12 = 0.0035 (insignificant), r22 = 0.395 (significant) and:

ym = 1.74 t/ha                        for ss < 4.93 (breakpoint)
ym = −0.129 ss + 2.38 t/ha     for ss > 4.93 (breakpoint)indicating that soil salinities < 4.93 ds/m are safe and soil salinities > 4.93 ds/m reduce the yield @ 0.129 t/ha per unit increase of soil salinity.
the figure also shows confidence intervals and uncertainty as elaborated hereunder.


== test procedures ==

the following statistical tests are used to determine the type of trend:

significance of the breakpoint (bp) by expressing bp as a function of  regression coefficients a1 and a2 and the means y1 and y2 of the y-data and the means x1 and x2 of the x data (left and right of bp), using the laws of propagation of errors in additions and multiplications to compute the standard error (se) of bp, and applying student's t-test
significance of a1 and a2 applying student's t-distribution and the standard error se of a1 and a2
significance of the difference of a1 and a2 applying student's t-distribution using the se of their difference.
significance of the difference of y1 and y2 applying student's t-distribution using the se of their difference.
a more formal statistical approach to test for the existence of a breakpoint, is via the pseudo score test which does not require estimation of the segmented line.in addition, use is made of the correlation coefficient of all data (ra), the coefficient of determination or coefficient of explanation, confidence intervals of the regression functions, and anova analysis.the coefficient of determination for all data (cd), that is to be maximized under the conditions set by the significance tests, is found from:

  
    
      
        
          c
          
            d
          
        
        =
        1
        −
        
          
            
              ∑
              (
              y
              −
              
                y
                
                  r
                
              
              
                )
                
                  2
                
              
            
            
              ∑
              (
              y
              −
              
                y
                
                  a
                
              
              
                )
                
                  2
                
              
            
          
        
      
    
    {\displaystyle c_{d}=1-{\sum (y-y_{r})^{2} \over \sum (y-y_{a})^{2}}}
  where yr is the expected (predicted) value of y according to the former regression equations and ya is the average of all y values.
the cd coefficient ranges between 0 (no explanation at all) to 1 (full explanation, perfect match). 
in a pure, unsegmented, linear regression, the values of cd and ra2 are equal. in a segmented regression, cd needs to be significantly larger than ra2 to justify the segmentation.
the optimal value of the breakpoint may be found such that the cd coefficient is maximum.


== no-effect range ==

segmented regression is often used to detect over which range an explanatory variable (x) has no effect on the dependent variable (y), while beyond the reach there is a clear response, be it positive or negative.
the reach of no effect may be found at the initial part of x domain or conversely at its last part. for the "no effect" analysis, application of the least squares method for the segmented regression analysis  may not be the most appropriate technique because the aim is rather to find the longest stretch over which the y-x relation can be considered to possess zero slope while beyond the reach the slope is significantly different from zero but knowledge about the best value of this slope is not material. the method to find the no-effect range is progressive partial regression  over the range, extending the range with small steps until the regression coefficient gets significantly different from zero.
in the next figure the break point is found at x=7.9 while for the same data (see blue figure above for mustard yield), the least squares method yields a break point only at x=4.9. the latter value is lower, but the fit of the data beyond the break point is better. hence, it will depend on the purpose of the analysis which method needs to be employed.


== see also ==
chow test
simple regression
linear regression
ordinary least squares
multivariate adaptive regression splines
local regression
regression discontinuity design
stepwise regression
segreg (software) for segmented regression


== references ==