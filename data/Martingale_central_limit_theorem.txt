in probability theory, the central limit theorem says that, under certain conditions, the sum of many independent identically-distributed random variables, when scaled appropriately, converges in distribution to a standard normal distribution.  the martingale central limit theorem generalizes this result for random variables to martingales, which are stochastic processes where the change in the value of the process from time t to time t + 1 has expectation zero, even conditioned on previous outcomes.


== statement ==
here is a simple version of the martingale central limit theorem: let

  
    
      
        
          x
          
            1
          
        
        ,
        
          x
          
            2
          
        
        ,
        …
        
      
    
    {\displaystyle x_{1},x_{2},\dots \,}
   be a martingale with bounded increments; that is, suppose

  
    
      
        e
        ⁡
        [
        
          x
          
            t
            +
            1
          
        
        −
        
          x
          
            t
          
        
        |
        
          x
          
            1
          
        
        ,
        …
        ,
        
          x
          
            t
          
        
        ]
        =
        0
        
        ,
      
    
    {\displaystyle \operatorname {e} [x_{t+1}-x_{t}\vert x_{1},\dots ,x_{t}]=0\,,}
  and

  
    
      
        
          |
        
        
          x
          
            t
            +
            1
          
        
        −
        
          x
          
            t
          
        
        
          |
        
        ≤
        k
      
    
    {\displaystyle |x_{t+1}-x_{t}|\leq k}
  almost surely for some fixed bound k and all t. also assume that 
  
    
      
        
          |
        
        
          x
          
            1
          
        
        
          |
        
        ≤
        k
      
    
    {\displaystyle |x_{1}|\leq k}
   almost surely.
define

  
    
      
        
          σ
          
            t
          
          
            2
          
        
        =
        e
        ⁡
        [
        (
        
          x
          
            t
            +
            1
          
        
        −
        
          x
          
            t
          
        
        
          )
          
            2
          
        
        
          |
        
        
          x
          
            1
          
        
        ,
        …
        ,
        
          x
          
            t
          
        
        ]
        ,
      
    
    {\displaystyle \sigma _{t}^{2}=\operatorname {e} [(x_{t+1}-x_{t})^{2}|x_{1},\ldots ,x_{t}],}
  and let

  
    
      
        
          τ
          
            ν
          
        
        =
        min
        
          {
          
            t
            :
            
              ∑
              
                i
                =
                1
              
              
                t
              
            
            
              σ
              
                i
              
              
                2
              
            
            ≥
            ν
          
          }
        
        .
      
    
    {\displaystyle \tau _{\nu }=\min \left\{t:\sum _{i=1}^{t}\sigma _{i}^{2}\geq \nu \right\}.}
  then

  
    
      
        
          
            
              x
              
                
                  τ
                  
                    ν
                  
                
              
            
            
              ν
            
          
        
      
    
    {\displaystyle {\frac {x_{\tau _{\nu }}}{\sqrt {\nu }}}}
  converges in distribution to the normal distribution with mean 0 and variance 1 as 
  
    
      
        ν
        →
        +
        ∞
        
      
    
    {\displaystyle \nu \to +\infty \!}
  . more explicitly,

  
    
      
        
          lim
          
            ν
            →
            +
            ∞
          
        
        p
        ⁡
        
          (
          
            
              
                
                  x
                  
                    
                      τ
                      
                        ν
                      
                    
                  
                
                
                  ν
                
              
            
            <
            x
          
          )
        
        =
        φ
        (
        x
        )
        =
        
          
            1
            
              2
              π
            
          
        
        
          ∫
          
            −
            ∞
          
          
            x
          
        
        exp
        ⁡
        
          (
          
            −
            
              
                
                  u
                  
                    2
                  
                
                2
              
            
          
          )
        
        
        d
        u
        ,
        
        x
        ∈
        
          r
        
        .
      
    
    {\displaystyle \lim _{\nu \to +\infty }\operatorname {p} \left({\frac {x_{\tau _{\nu }}}{\sqrt {\nu }}}<x\right)=\phi (x)={\frac {1}{\sqrt {2\pi }}}\int _{-\infty }^{x}\exp \left(-{\frac {u^{2}}{2}}\right)\,du,\quad x\in \mathbb {r} .}
  


== the sum of variances must diverge to infinity ==
the statement of the above result implicitly assumes the variances sum to infinity, so the following holds with probability 1:

  
    
      
        
          ∑
          
            t
            =
            1
          
          
            ∞
          
        
        
          σ
          
            t
          
          
            2
          
        
        =
        ∞
      
    
    {\displaystyle \sum _{t=1}^{\infty }\sigma _{t}^{2}=\infty }
  this ensures that with probability 1:

  
    
      
        
          τ
          
            v
          
        
        <
        ∞
        ,
        ∀
        v
        ≥
        0
      
    
    {\displaystyle \tau _{v}<\infty ,\forall v\geq 0}
  this condition is violated, for example, by a martingale that is defined to be zero almost surely for all time.


== intuition on the result ==
the result can be intuitively understood by writing the ratio as a summation: 

  
    
      
        
          
            
              x
              
                
                  τ
                  
                    v
                  
                
              
            
            
              v
            
          
        
        =
        
          
            
              x
              
                1
              
            
            
              v
            
          
        
        +
        
          
            1
            
              v
            
          
        
        
          ∑
          
            i
            =
            1
          
          
            
              τ
              
                v
              
            
            −
            1
          
        
        (
        
          x
          
            i
            +
            1
          
        
        −
        
          x
          
            i
          
        
        )
        ,
        ∀
        
          τ
          
            v
          
        
        ≥
        1
      
    
    {\displaystyle {\frac {x_{\tau _{v}}}{\sqrt {v}}}={\frac {x_{1}}{\sqrt {v}}}+{\frac {1}{\sqrt {v}}}\sum _{i=1}^{\tau _{v}-1}(x_{i+1}-x_{i}),\forall \tau _{v}\geq 1}
  the first term on the right-hand-side asymptotically converges to zero, while the second term is qualitatively similar to the summation formula for the central limit theorem in the simpler case of i.i.d. random variables. while the terms in the above expression are not necessarily i.i.d., they are uncorrelated and have zero mean.  indeed:

  
    
      
        e
        [
        (
        
          x
          
            i
            +
            1
          
        
        −
        
          x
          
            i
          
        
        )
        ]
        =
        0
        ,
        ∀
        i
        ∈
        {
        1
        ,
        2
        ,
        3
        ,
        .
        .
        .
        }
      
    
    {\displaystyle e[(x_{i+1}-x_{i})]=0,\forall i\in \{1,2,3,...\}}
  
  
    
      
        e
        [
        (
        
          x
          
            i
            +
            1
          
        
        −
        
          x
          
            i
          
        
        )
        (
        
          x
          
            j
            +
            1
          
        
        −
        
          x
          
            j
          
        
        )
        ]
        =
        0
        ,
        ∀
        i
        ≠
        j
        ,
        i
        ,
        j
        ∈
        {
        1
        ,
        2
        ,
        3
        ,
        .
        .
        .
        }
      
    
    {\displaystyle e[(x_{i+1}-x_{i})(x_{j+1}-x_{j})]=0,\forall i\neq j,i,j\in \{1,2,3,...\}}
  


== references ==
many other variants on the martingale central limit theorem can be found in:

hall, peter; heyde, c. c. (1980). martingale limit theory and its application. new york: academic press. isbn 0-12-319350-8.note, however, that the proof of theorem 5.4 in hall & heyde contains an error.  for further discussion, see 

bradley, richard (1988). "on some results of mi gordin: a clarification of a misunderstanding". journal of theoretical probability. springer. 1 (2): 115–119. doi:10.1007/bf01046930.